# -*- coding: utf-8 -*-
"""sa_using_lr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cujTgu5cBfQvEFpSvMu5WGdhep5slMDh
"""

import numpy as np
import pandas as pd
import re
import nltk
import joblib
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score, classification_report
import os
import shutil
import tarfile
import urllib.request

nltk.download('stopwords')
nltk.download('punkt')

data_url = "https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
data_path = "aclImdb_v1.tar.gz"
extract_path = "aclImdb"

if not os.path.exists(extract_path):
    print("Downloading IMDB dataset...")
    urllib.request.urlretrieve(data_url, data_path)
    print("Extracting dataset...")
    with tarfile.open(data_path, "r:gz") as tar:
        tar.extractall()
    print("Dataset ready.")

def load_imdb_data(directory):
    texts, labels = [], []
    for label, sentiment in enumerate(["neg", "pos"]):
        folder_path = os.path.join(directory, sentiment)
        for filename in os.listdir(folder_path):
            with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as file:
                texts.append(file.read())
                labels.append(label)
    return texts, labels

import nltk
nltk.download('punkt_tab')

train_reviews, train_labels = load_imdb_data("aclImdb/train")
test_reviews, test_labels = load_imdb_data("aclImdb/test")

reviews = train_reviews + test_reviews
labels = train_labels + test_labels

# Preprocessing
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    words = nltk.word_tokenize(text)
    words = [word for word in words if word not in stopwords.words('english')]
    stemmer = PorterStemmer()
    words = [stemmer.stem(word) for word in words]
    return ' '.join(words)

# Apply preprocessing
processed_reviews = [preprocess_text(str(review)) for review in reviews]

# Convert text to TF-IDF vectors
vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))
X = vectorizer.fit_transform(processed_reviews)
y = np.array(labels)

# Split dataset (balanced stratified sampling)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Train Logistic Regression model using SGD (supports epochs)
model = SGDClassifier(loss='log_loss', max_iter=5000, tol=1e-4)  # Increased iterations
history=model.fit(X_train, y_train)

# Save the model and vectorizer
joblib.dump(model, "logistic_regression_imdb.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

# Predictions
y_pred = model.predict(X_test)

# Model evaluation
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')
print(classification_report(y_test, y_pred))

# Load and test saved model
loaded_model = joblib.load("logistic_regression_imdb.pkl")
loaded_vectorizer = joblib.load("tfidf_vectorizer.pkl")

def predict_sentiment(review):
    processed_review = preprocess_text(review)
    review_vectorized = loaded_vectorizer.transform([processed_review])
    prediction = loaded_model.predict(review_vectorized)
    return "Positive" if prediction[0] == 1 else "Negative"

print(predict_sentiment("This movie was soo bad!"))

print(predict_sentiment("This movie was amazing!"))

print(predict_sentiment("great movie man"))

print(predict_sentiment("Saw a good movie really!!! made my day"))